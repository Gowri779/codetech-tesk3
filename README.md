# codetech-tesk3
# -*- coding: utf-8 -*-
"""SentimentAnalysis_TFIDF_LogisticRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/... (your colab link)

This notebook demonstrates sentiment analysis on customer reviews using TF-IDF vectorization and logistic regression.

**1. Import Libraries**
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
import nltk
from nltk.corpus import stopwords
import string
import re

nltk.download('stopwords')

"""**2. Load the Dataset**

For this example, we'll use a sample dataset. Replace `'reviews.csv'` with your actual dataset path. The dataset should contain 'review' and 'sentiment' columns. Sentiment should be numerical (e.g., 0 for negative, 1 for positive).
"""

# Sample dataset creation for demonstration. Replace with your dataset loading.
data = {'review': ["This product is great!", "Terrible experience, would not recommend.", "It's okay, nothing special.", "Amazing quality, very satisfied.", "Extremely disappointed with the service."],
        'sentiment': [1, 0, 0, 1, 0]}
df = pd.DataFrame(data)

# If you have a CSV file:
# df = pd.read_csv('reviews.csv')

"""**3. Preprocessing**"""

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^\w\s]', '', text) #remove punctuation
    stop_words = set(stopwords.words('english'))
    text = ' '.join([word for word in text.split() if word not in stop_words])
    return text

df['review'] = df['review'].apply(preprocess_text)

"""**4. Split the Data**"""

X = df['review']
y = df['sentiment']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""**5. TF-IDF Vectorization**"""

tfidf_vectorizer = TfidfVectorizer(max_features=5000) # Limit features for efficiency
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

"""**6. Logistic Regression Model**"""

logistic_regression = LogisticRegression(random_state=42, max_iter=1000) # increased max_iter
logistic_regression.fit(X_train_tfidf, y_train)

"""**7. Make Predictions**"""

y_pred = logistic_regression.predict(X_test_tfidf)

"""**8. Evaluate the Model**"""

print("Classification Report:\n", classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))

"""**9. Analyzing the Results**

* **Accuracy:** The accuracy score represents the overall correctness of the model's sentiment predictions.
* **Classification Report:** The classification report provides detailed metrics for each sentiment class (positive and negative), including precision, recall, and F1-score.
* **Preprocessing Impact:** The preprocessing steps (lowercasing, punctuation removal, stop word removal) help to clean the text data and improve the model's performance.
* **TF-IDF Effectiveness:** TF-IDF vectorization converts the text data into numerical features that the logistic regression model can understand. It assigns higher weights to words that are more important for distinguishing between sentiment classes.
* **Logistic Regression Suitability:** Logistic regression is a suitable algorithm for binary classification tasks like sentiment analysis. It's relatively simple, efficient, and often performs well with text data.

**Further Exploration:**

* **Hyperparameter Tuning:** Experiment with different hyperparameters for the TF-IDF vectorizer and logistic regression model to optimize performance.
* **Different Vectorization Techniques:** Try other vectorization techniques, such as CountVectorizer or word embeddings (e.g., Word2Vec, GloVe, or transformer-based embeddings).
* **More Complex Models:** Explore more advanced models, such as support vector machines (SVMs), naive Bayes, or deep learning models (e.g., recurrent neural networks or transformers).
* **Larger Datasets:** Train the model on larger and more diverse datasets to improve its generalization ability.
* **Cross-Validation:** Use cross-validation to evaluate the model's performance more robustly.
* **Sentiment Intensity Analysis:** Investigate sentiment intensity by using libraries like VADER.
* **Error Analysis:** Examine the misclassified reviews to understand the model's weaknesses and identify areas for improvement.
* **Handle Imbalanced Data:** If the sentiment distribution is imbalanced, use techniques like oversampling or undersampling to address the issue.
"""
